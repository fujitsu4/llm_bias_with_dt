# llm_bias_with_dt

## A.Project overview
This project contains scripts used in the article **"Exploring Biases in BERT through Attention Scores: A Decision Tree Approach"***.
This is a research-oriented framework designed to analyze and characterize bias-related decision patterns in BERT models using interpretable decision trees.

The project follows a structured pipeline that:

1. Clean and prepare datasets,
2. Extracts attention scores from pretrained and untrained BERT models,
3. Derives linguistic and statistical token-level features,
4. Trains decision trees at each transformer layer,
5. Analyzes stable feature usage and compositional decision patterns across layers and random seeds.

Particular emphasis is placed on **interpretability**, **reproducibility**, and **robustness across random initializations**.

All major processing steps are accompanied by dedicated verification scripts to ensure the correctness of intermediate and final results.

The framework supports both **pretrained** BERT and **untrained** BERT models, enabling a systematic comparison between emergent structures induced by training and architectural biases.

## B.Project structure
LLM_BIAS_WITH_DT/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cleaned/                 # Filtered and merged datasets (AGNews, ArXiv, MNLI, SNLI)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ attention/               # Attention extraction and verification
â”‚   â”œâ”€â”€ bert/                    # BERT-based linguistic and statistical features
â”‚   â”œâ”€â”€ spacy/                   # SpaCy feature extraction
â”‚   â”œâ”€â”€ decision_tree/           # Decision tree training and validation
â”‚   â”œâ”€â”€ dt_analysis/             # Decision tree analysis and aggregation
â”‚   â”œâ”€â”€ prepare/                 # Dataset preparation scripts
â”‚   â”œâ”€â”€ seeds/                   # Seed generation utilities
â”‚   â”œâ”€â”€ utils/                   # Shared utilities
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ attention/               # Attention scores (samples + seeds list)
â”‚   â”œâ”€â”€ bert/                    # Extracted BERT features (samples)
â”‚   â”œâ”€â”€ decision_tree/           # Decision tree rules (pretrained / untrained)
â”‚   â”œâ”€â”€ dt_analysis/             # Final aggregated results (CSV + ZIP)
â”‚   â””â”€â”€ spacy/                   # SpaCy feature outputs
â”‚
â”œâ”€â”€ logs/                        # Execution and verification logs
â”‚
â”œâ”€â”€ run_attention_seeds.sh       # Batch execution for attention extraction
â”œâ”€â”€ run_decision_tree_seeds.sh   # Batch execution for decision tree training
â”‚
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE

## B.Installation

```bash
git clone https://github.com/USER/llm_bias_with_dt
cd llm_bias_with_dt

python3 -m venv venv
source venv/bin/activate

pip install -r requirements.txt
```

## C.How to Run
1. Prepare datasets
python src/prepare/prepare_dataset_snli.py
python src/prepare/prepare_dataset_mnli.py

2. Merge
python src/merge/merge_datasets.py

3. Compute linguistic features
python src/features/compute_spacy_features.py

4. Verify integrity
python src/features/verify_spacy_features.py

## ğŸ“ Data Availability and Repository Structure

To keep this repository lightweight, readable, and compliant with GitHubâ€™s recommended size constraints, **only lightweight sample files of the intermediate outputs are included here**.  
These sample files (5 lines each) are provided exclusively for **illustration, documentation, and structural transparency**.

---

### ğŸ”¹ Why only sample files?

Some intermediate CSV files generated during the experiments (e.g., BERT token features, attention matrices, statistical descriptors) originally exceed **30â€“100 MB per file**, and the complete pipeline produces **hundreds of such files**.  
Including them directly in the repository would:

- inflate the repository size unnecessarily,  
- violate large file best practices,  
- slow down cloning and CI workflows,  
- reduce overall readability for users and reviewers.

Therefore, this repository includes files such as:

bert_final_features_SAMPLE.csv
bert_basic_features_SAMPLE.csv
spacy_features_SAMPLE.csv
attention_top5_pretrained_SAMPLE.csv


Each sample keeps **only the first 5 rows**, allowing readers to understand:

- the file schema,  
- the column definitions,  
- the preprocessing workflow,  
- and how each component interacts in the pipeline,  

without including full, heavy intermediate outputs.

---

## ğŸ“¦ Full Reproducibility

The **complete intermediate results**, including all intermediate and large output files, are archived externally (Google Drive) to ensure:

- long-term preservation,  
- stable access,  
- citable references,  
- compliance with FAIR principles.  

To reproduce the full pipeline, simply follow all the commands listed at the beginning of this readme. The code will place them automatically into the correct directories (without any truncation of the results).

---

## ğŸ“ Debug Samples

The folder `outputs/debug_samples/` contains a minimal and lightweight subset of
debugging outputs used to illustrate the internal structure of the pipeline.
Only one complete example is kept for each setting (pretrained / untrained), for
documentation purposes. The full debug output originally generated during the
runs has been intentionally omitted to keep the repository clean and compact,
as it is not required for reproducibility or analysis.

---

## ğŸ“ Notes

- All sample files follow the naming pattern `*_sample.csv` to clearly distinguish them from full data files.  
- The repository is intentionally structured to remain **fast to clone**, **easy to inspect**, and **fully reproducible** once external datasets are provided.
-The `data/cleaned` and `logs/` folders are kept in full and were not cleaned or reduced.
They contain the processed datasets and the complete processing logs required to ensure full reproducibility and transparency of the experiments.

---

## License
This project is licensed under the MIT License â€“ see the LICENSE file for details.